import { pfctBlogUrls } from "../src/lib/pfctBlogUrls";

type BlogData = {
  url: string;
  slug: string;
  title: string | null;
  description: string | null;
  ogImage: string | null;
  bodyText: string | null;
  wordCount: number;
  error?: string;
};

async function crawlBlog(url: string): Promise<BlogData> {
  const slug = url.replace("https://blog.pfct.co.kr/", "");
  
  try {
    const response = await fetch(url, {
      headers: {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
      },
    });
    
    if (!response.ok) {
      return { url, slug, title: null, description: null, ogImage: null, bodyText: null, wordCount: 0, error: `HTTP ${response.status}` };
    }
    
    const html = await response.text();
    
    // Extract meta tags
    const titleMatch = html.match(/<meta\s+property="og:title"\s+content="([^"]*)"/) ||
                       html.match(/<title>([^<]*)<\/title>/);
    const descMatch = html.match(/<meta\s+property="og:description"\s+content="([^"]*)"/) ||
                      html.match(/<meta\s+name="description"\s+content="([^"]*)"/);
    const imageMatch = html.match(/<meta\s+property="og:image"\s+content="([^"]*)"/);
    
    // Extract body text (remove scripts, styles, tags)
    let bodyText = html
      .replace(/<script[^>]*>[\s\S]*?<\/script>/gi, "")
      .replace(/<style[^>]*>[\s\S]*?<\/style>/gi, "")
      .replace(/<[^>]+>/g, " ")
      .replace(/\s+/g, " ")
      .trim();
    
    // Limit body text length
    bodyText = bodyText.slice(0, 5000);
    
    const wordCount = bodyText.split(/\s+/).length;
    
    return {
      url,
      slug,
      title: titleMatch?.[1]?.trim() || null,
      description: descMatch?.[1]?.trim() || null,
      ogImage: imageMatch?.[1] || null,
      bodyText,
      wordCount,
    };
  } catch (error) {
    return { url, slug, title: null, description: null, ogImage: null, bodyText: null, wordCount: 0, error: String(error) };
  }
}

async function main() {
  console.log(`크롤링 시작: ${pfctBlogUrls.length}개 블로그\n`);
  
  const results: BlogData[] = [];
  
  for (let i = 0; i < pfctBlogUrls.length; i++) {
    const url = decodeURIComponent(pfctBlogUrls[i]);
    console.log(`[${i + 1}/${pfctBlogUrls.length}] ${url.slice(0, 60)}...`);
    
    const data = await crawlBlog(url);
    results.push(data);
    
    // Rate limiting
    await new Promise(resolve => setTimeout(resolve, 200));
  }
  
  // Save to file
  const outputPath = "./src/lib/pfctBlogData.ts";
  const fileContent = `// Auto-generated by crawl-blogs.ts
// Generated at: ${new Date().toISOString()}

export type BlogData = {
  url: string;
  slug: string;
  title: string | null;
  description: string | null;
  ogImage: string | null;
  bodyText: string | null;
  wordCount: number;
};

export const pfctBlogData: BlogData[] = ${JSON.stringify(results.map(r => ({
    url: r.url,
    slug: r.slug,
    title: r.title,
    description: r.description,
    ogImage: r.ogImage,
    bodyText: r.bodyText,
    wordCount: r.wordCount,
  })), null, 2)};
`;

  await Bun.write(outputPath, fileContent);
  
  // Summary
  const successCount = results.filter(r => !r.error).length;
  const errorCount = results.filter(r => r.error).length;
  
  console.log(`\n=== 크롤링 완료 ===`);
  console.log(`성공: ${successCount}개`);
  console.log(`실패: ${errorCount}개`);
  console.log(`저장: ${outputPath}`);
  
  if (errorCount > 0) {
    console.log(`\n실패한 URL:`);
    results.filter(r => r.error).forEach(r => console.log(`  - ${r.slug}: ${r.error}`));
  }
}

main();

