# AI Challenge Hub - 문제 출제 철학

## 개요

AI의 성능을 검증하는 벤치마크는 넘쳐나지만, 인간의 활용 역량을 검증할 잣대는 부재한 현실.
이 플랫폼은 'AI를 잘 쓰는 사람'을 찾고 평가하기 위해 만들어졌습니다.

---

## 우리가 찾는 사람: 문제 해결자

단순히 프롬프트를 잘 짜거나 최신 툴을 아는 사람이 아닌:

1. 문제를 명확히 정의하고
2. AI를 동료로 삼아 협업하며
3. 매 순간 최적의 의사결정을 내릴 수 있는 사람

---

## 3대 출제 원칙

### 원칙 1: Human-in-the-loop

사람의 분석 → AI의 문제 해결 → 사람의 검증

- AI가 전적으로 문제를 해결하는 것이 아님
- 엔진(AI)을 어디로 이끌지 결정하고 결과물의 품질을 책임지는 것은 사람
- 복사-붙여넣기 한 번으로 풀리는 "딸깍" 문제 지양

### 원칙 2: 낮은 진입 장벽, 높은 천장

- 진입: 누구나 이해할 수 있을 만큼 직관적
- 풀이: 깊이가 있어야 함
- 정답은 명확하되, AI가 단번에 풀 수 없는 구조 설계
- AI의 기술적 약점을 문제에 심어 검증 없이는 오답 확률이 높도록 구성

### 원칙 3: 해법의 다양성

- 특정 프레임워크나 단일 풀이 방법 강제하지 않음
- 출제자도 상상 못한 창의적 접근 허용
- "AI를 이렇게도 쓸 수 있구나" 하는 발견의 경험 제공

---

## 문제 패턴 분류

| 패턴 | 핵심 역량 | 내용 |
|------|-----------|------|
| P1. 분석 및 정의 | Insight | 복합 데이터에서 의미 있는 문제/기회 발견 |
| P2. 구현 및 자동화 | Action | 실제 작동하는 코드/워크플로 구현 |
| P3. 전략 및 창의 | Persuasion | 비기술 이해관계자에게 설득력 있게 전달 |
| P4. 최적화/의사결정 | Decision | 제약 조건 하에서 최적 의사결정 |

---

## 난이도 체계

### 난이도 등급

| 등급 | 이름 | 설명 |
|------|------|------|
| Lv.1 | 입문 | 기본 데이터 처리, 객관식 중심, AI와 함께 바로 풀 수 있는 수준 |
| Lv.2 | 중급 | 데이터 조인/집계, 코드 구현 필요, 일부 검증 필요 |
| Lv.3 | 고급 | 멀티모달 분석, 복잡한 규칙 해석, 도메인 이해 필요 |
| Lv.4 | 전문가 | 최적화 알고리즘, 창의적 접근 필수, AI 단독 해결 불가 |

### 문항 구조: 난이도 사다리

하나의 문제 안에서 점진적으로 난이도를 높이는 구조:

- **시작 문항 (Easy)**: 진입 장벽을 낮춰 포기하지 않도록 유도
- **힌트 문항 (Medium)**: 킬러 문항을 풀기 위한 단서이자 빌드업
- **킬러 문항 (Hard)**: 변별력의 핵심, 복합 추론과 인간의 검증이 필수

### 답변 유형별 난이도

| 유형 | 상대 난이도 | 특성 |
|------|-------------|------|
| 객관식 (단일 선택) | 낮음 | 보기가 힌트 역할 |
| 객관식 (다중 선택) | 중간 | 조합 고려 필요 |
| 주관식 (단답형) | 높음 | 형식까지 맞춰야 함 |
| 주관식 (서술형) | 매우 높음 | 검증 난이도 높음 |

---

## 검증 구조 설계

문제 해결 과정에서 사람의 검증 역량을 다양한 방식으로 측정:

| 유형 | 설명 | 예시 |
|------|------|------|
| 명시적 검증 | 검증 방법을 문제에서 직접 제시 | "검증 데이터셋을 직접 구성하세요" |
| 시스템적 검증 | 시스템이 제출 결과에 대한 피드백 제공 | 제출 → 점수/피드백 → 재제출 루프 |
| 암묵적 검증 | 언급 없지만 검증하지 않으면 오답 확률 높음 | AI 할루시네이션 유발 요소 배치 |

---

## 문제 출제 체크리스트

### 기본 요건
- 정답이 명확한가?
- 채점 로직이 구현 가능한가?
- 문제 설명이 명확한가?

### Human-in-the-loop 검증
- AI에게 복붙만 해서 풀리지 않는가?
- 사람의 분석/검증이 필요한 요소가 있는가?
- AI의 약점을 활용한 함정이 있는가?

### 난이도 구조 검증
- Easy → Hard 사다리 구조인가?
- 킬러 문항이 존재하는가?
- 검증 포인트가 명확한가?

### 공정성 검증
- 특정 도메인 경험이 과도하게 유리하지 않은가?
- 배점이 노력 대비 적절한가?
- 어뷰징 가능성은 없는가?

---

## 현재 챌린지 평가

| 챌린지 | 난이도 | Human-in-the-loop | 딸깍 방지 |
|--------|--------|-------------------|-----------|
| 스마트 배달 배차 분석 | Lv.1 입문 | 약함 | 약함 |
| PFCT Blog Insight | Lv.2 중급 | 중간 | 중간 |
| OTT 콘텐츠 흥행 분석 | Lv.2 중급 | 중간 | 중간 |
| 드론 AI 비상 상황 판단 | Lv.3 고급 | 강함 | 강함 |
| 보이저 3호 외계 신호 해독 | Lv.3 고급 | 강함 | 강함 |
| 스마트 물류 로봇 동선 최적화 | Lv.4 전문가 | 강함 | 강함 |

---

이 문서는 AI Challenge Hub의 문제 출제 원칙을 정리한 것입니다.
새 문제 추가 시 이 철학에 맞는지 검토해주세요.
