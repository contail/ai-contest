# AI Challenge Hub - 문제 출제 철학

## 개요

AI의 성능을 검증하는 벤치마크는 넘쳐나지만, 인간의 활용 역량을 검증할 잣대는 부재한 현실.
이 플랫폼은 'AI를 잘 쓰는 사람'을 찾고 평가하기 위해 만들어졌습니다.

---

## 우리가 찾는 사람: 문제 해결자

단순히 프롬프트를 잘 짜거나 최신 툴을 아는 사람이 아닌:

1. 문제를 명확히 정의하고
2. AI를 동료로 삼아 협업하며
3. 매 순간 최적의 의사결정을 내릴 수 있는 사람

---

## 3대 출제 원칙

### 원칙 1: Human-in-the-loop

사람의 분석 → AI의 문제 해결 → 사람의 검증

- AI가 전적으로 문제를 해결하는 것이 아님
- 엔진(AI)을 어디로 이끌지 결정하고 결과물의 품질을 책임지는 것은 사람
- 복사-붙여넣기 한 번으로 풀리는 "딸깍" 문제 지양

### 원칙 2: 낮은 진입 장벽, 높은 천장

- 진입: 누구나 이해할 수 있을 만큼 직관적
- 풀이: 깊이가 있어야 함
- 정답은 명확하되, AI가 단번에 풀 수 없는 구조 설계
- AI의 기술적 약점을 문제에 심어 검증 없이는 오답 확률이 높도록 구성

### 원칙 3: 해법의 다양성

- 특정 프레임워크나 단일 풀이 방법 강제하지 않음
- 출제자도 상상 못한 창의적 접근 허용
- "AI를 이렇게도 쓸 수 있구나" 하는 발견의 경험 제공

---

## 문제 패턴 분류

| 패턴 | 핵심 역량 | 내용 |
|------|-----------|------|
| P1. 분석 및 정의 | Insight | 복합 데이터에서 의미 있는 문제/기회 발견 |
| P2. 구현 및 자동화 | Action | 실제 작동하는 코드/워크플로 구현 |
| P3. 전략 및 창의 | Persuasion | 비기술 이해관계자에게 설득력 있게 전달 |
| P4. 최적화/의사결정 | Decision | 제약 조건 하에서 최적 의사결정 |

---

## 난이도 체계

### 난이도 등급

| 등급 | 이름 | 설명 |
|------|------|------|
| Lv.1 | 입문 | 기본 데이터 처리, 객관식 중심, AI와 함께 바로 풀 수 있는 수준 |
| Lv.2 | 중급 | 데이터 조인/집계, 코드 구현 필요, 일부 검증 필요 |
| Lv.3 | 고급 | 멀티모달 분석, 복잡한 규칙 해석, 도메인 이해 필요 |
| Lv.4 | 전문가 | 최적화 알고리즘, 창의적 접근 필수, AI 단독 해결 불가 |
| Lv.5 | 하드코어 | 바이너리 파싱, 코드 분석, 크로스파일 추론, 명세 없이 역공학 필요 |
| Lv.6 | 심연 | 거짓 정보 간파, 500MB+ 대용량 스트리밍, 역발상 필터링, AI 단독 해결 불가능 |

### 문항 구조: 난이도 사다리

하나의 문제 안에서 점진적으로 난이도를 높이는 구조:

- **시작 문항 (Easy)**: 진입 장벽을 낮춰 포기하지 않도록 유도
- **힌트 문항 (Medium)**: 킬러 문항을 풀기 위한 단서이자 빌드업
- **킬러 문항 (Hard)**: 변별력의 핵심, 복합 추론과 인간의 검증이 필수

### 답변 유형별 난이도

| 유형 | 상대 난이도 | 특성 |
|------|-------------|------|
| 객관식 (단일 선택) | 낮음 | 보기가 힌트 역할 |
| 객관식 (다중 선택) | 중간 | 조합 고려 필요 |
| 주관식 (단답형) | 높음 | 형식까지 맞춰야 함 |
| 주관식 (구조화 데이터) | 높음 | JSON, CSV 등 정해진 스키마로 제출 |
| 주관식 (서술형) | 매우 높음 | 검증 난이도 높음 |

---

## 데이터셋 설계 원칙

### 핵심 철학: 사람이 직접 해결 불가능한 규모

AI 활용 역량을 검증하려면, **사람이 수작업으로 풀 수 없는 규모**의 데이터가 필수.
눈으로 훑어보고 답을 찾는 "딸깍"을 원천 차단한다.

### 데이터셋 복잡도 기준

| 등급 | 파일 구조 | 데이터 규모 | 예시 |
|------|-----------|-------------|------|
| Lv.1 | 단일 파일 | 100줄 이하 | `data.csv` 하나 |
| Lv.2 | 2~5개 파일 | 1,000줄 이상 | 여러 CSV 조인 필요 |
| Lv.3 | 5~10개 파일 + 폴더 구조 | 10,000줄 이상 | 로그 + 메타데이터 + 이미지 |
| Lv.4 | 10개 이상 파일 + 중첩 폴더 | 100,000줄 이상 | 멀티모달, 크로스파일 분석 필수 |

### 데이터셋 설계 체크리스트

- [ ] 사람이 직접 Ctrl+F로 답을 찾을 수 없는가?
- [ ] 여러 파일을 조합해야 답이 나오는가? (크로스파일 분석)
- [ ] AI 없이 엑셀/메모장으로 분석하면 몇 시간 이상 걸리는가?
- [ ] 로그 파일의 경우 최소 10,000줄 이상인가?
- [ ] 폴더 구조가 있어 탐색 자체가 과제인가?

### 권장 데이터 유형

| 유형 | 설명 | 난이도 기여 |
|------|------|-------------|
| 대용량 로그 | JSON/TXT, 10만줄+ | 패턴 추출 필수 |
| 중첩 폴더 구조 | `data/year/month/day/` | 탐색 + 집계 |
| 멀티모달 | 이미지 + 텍스트 + 로그 | 크로스 검증 |
| 비정형 텍스트 | 자연어 문서, 이메일 | 파싱 + 해석 |
| 인코딩/난독화 | Base64, 암호화 | 전처리 필수 |

---

## 지문 설계 원칙

### 핵심 철학: 문제를 읽는 것부터 도전

지문 자체가 쉬우면 AI에게 그대로 복붙하게 된다.
**지문 해석 → 요구사항 정의 → 문제 해결** 전 과정에서 사람의 판단이 필요하도록 설계.

### 지문 난이도 기법

| 기법 | 설명 | 예시 |
|------|------|------|
| 암묵적 조건 | 모든 조건을 명시하지 않음 | "일반적인 상황에서..." |
| 도메인 용어 | 전문 용어 사용 | "FIFO 기준으로 처리" |
| 복합 조건 | 여러 조건을 한 문장에 | "A이면서 B가 아닌 경우 중 C를 만족하는" |
| 함정 표현 | 오해하기 쉬운 표현 | "포함하지 않는" vs "제외한" |
| 실제 업무 시뮬레이션 | 비즈니스 맥락 부여 | "팀장에게 보고할 요약을 작성하세요" |

### 지문 설계 체크리스트

- [ ] 지문을 그대로 AI에 복붙하면 오답이 나오는가?
- [ ] 요구사항을 정확히 파악하려면 여러 번 읽어야 하는가?
- [ ] 숨겨진 조건이나 함정이 있는가?
- [ ] 도메인 지식이나 맥락 이해가 필요한가?
- [ ] "무엇을 물어보는지" 정의하는 것 자체가 과제인가?

---

## 답변 포맷 설계

### 핵심 철학: 형식도 역량의 일부

단순 텍스트 답변보다 구조화된 포맷을 요구하면:
- AI 출력 검증이 필요해짐
- 형식 오류로 인한 오답 가능성
- 실무 역량과 연결

### 답변 포맷 유형

| 포맷 | 난이도 | 활용 상황 |
|------|--------|-----------|
| 단순 텍스트 | 낮음 | 입문 문제 |
| 숫자 (정수/소수점) | 중간 | 계산 결과, 반올림 규칙 지정 |
| 리스트 (콤마 구분) | 중간 | 여러 항목 나열 |
| JSON 객체 | 높음 | 구조화된 결과물 |
| JSON 배열 | 높음 | 다중 결과 정렬 포함 |
| 특정 스키마 JSON | 매우 높음 | 키 이름, 타입, 순서 모두 검증 |

### JSON 답변 예시

```json
// 예시: 상위 3개 항목을 점수 내림차순으로 제출
{
  "results": [
    {"id": "A001", "score": 95.2},
    {"id": "A003", "score": 87.1},
    {"id": "A007", "score": 82.5}
  ],
  "total_count": 3
}
```

### 답변 포맷 체크리스트

- [ ] 형식이 틀리면 오답 처리되는가?
- [ ] 정렬 순서가 답에 포함되는가?
- [ ] 소수점 자릿수, 반올림 규칙이 명시되어 있는가?
- [ ] JSON의 경우 스키마가 명확한가?

---

## 검증 구조 설계

문제 해결 과정에서 사람의 검증 역량을 다양한 방식으로 측정:

| 유형 | 설명 | 예시 |
|------|------|------|
| 명시적 검증 | 검증 방법을 문제에서 직접 제시 | "검증 데이터셋을 직접 구성하세요" |
| 시스템적 검증 | 시스템이 제출 결과에 대한 피드백 제공 | 제출 → 점수/피드백 → 재제출 루프 |
| 암묵적 검증 | 언급 없지만 검증하지 않으면 오답 확률 높음 | AI 할루시네이션 유발 요소 배치 |

---

## 문제 출제 체크리스트

### 기본 요건
- [ ] 정답이 명확한가?
- [ ] 채점 로직이 구현 가능한가?
- [ ] 문제 설명이 명확한가?

### Human-in-the-loop 검증
- [ ] AI에게 복붙만 해서 풀리지 않는가?
- [ ] 사람의 분석/검증이 필요한 요소가 있는가?
- [ ] AI의 약점을 활용한 함정이 있는가?

### 데이터셋 검증 (Lv.2 이상 필수)
- [ ] 사람이 수작업으로 풀 수 없는 규모인가?
- [ ] 여러 파일 간 크로스 분석이 필요한가?
- [ ] Ctrl+F로 답을 찾을 수 없는가?

### 지문 검증
- [ ] 지문 자체가 해석이 필요한가?
- [ ] 숨겨진 조건이나 함정이 있는가?
- [ ] 그대로 복붙하면 오답이 나오는가?

### 답변 포맷 검증
- [ ] 단순 텍스트가 아닌 구조화된 포맷을 요구하는가?
- [ ] 형식 오류 시 오답 처리 가능한가?
- [ ] 정렬, 소수점 등 세부 규칙이 명시되어 있는가?

### 난이도 구조 검증
- [ ] Easy → Hard 사다리 구조인가?
- [ ] 킬러 문항이 존재하는가?
- [ ] 검증 포인트가 명확한가?

### 공정성 검증
- [ ] 특정 도메인 경험이 과도하게 유리하지 않은가?
- [ ] 배점이 노력 대비 적절한가?
- [ ] 어뷰징 가능성은 없는가?

---

## 현재 챌린지 평가

| 챌린지 | 난이도 | 데이터 규모 | 지문 난이도 | 답변 포맷 | 딸깍 방지 |
|--------|--------|-------------|-------------|-----------|-----------|
| 스마트 배달 배차 분석 | Lv.1 | 단일 CSV | 쉬움 | 단답형 | 약함 |
| PFCT Blog Insight | Lv.2 | URL 목록 | 중간 | 단답형 | 중간 |
| OTT 콘텐츠 흥행 분석 | Lv.2 | 중형 CSV | 중간 | 단답형 | 중간 |
| 드론 AI 비상 상황 판단 | Lv.3 | 대용량 로그 | 어려움 | 단답형 | 강함 |
| 보이저 3호 외계 신호 해독 | Lv.3 | 멀티파일 | 어려움 | 단답형 | 강함 |
| 스마트 물류 로봇 동선 최적화 | Lv.4 | 대용량+시뮬 | 어려움 | 단답형 | 강함 |
| Ghost in the Shell: Protocol Zero | Lv.4 | 멀티파일+이미지 | 매우 어려움 | 단답형 | 매우 강함 |
| 작전명: 사일런트 시티 | Lv.5 | 바이너리+코드 | 극악 | 단답형 | 극강 |
| 심연의 목소리 | Lv.6 | 500MB 바이너리+거짓스펙 | 지옥 | 단답형 | 최강 |

### 개선 방향

현재 대부분의 챌린지가 **단답형** 답변 포맷을 사용 중.
향후 추가할 챌린지에서는 다음을 고려:

1. **JSON 제출 문제** - 구조화된 결과물 검증
2. **100,000줄+ 로그** - 수작업 분석 완전 차단
3. **10개 이상 파일** - 탐색 + 크로스분석 필수화
4. **복합 조건 지문** - 해석 자체가 과제

---

이 문서는 AI Challenge Hub의 문제 출제 원칙을 정리한 것입니다.
새 문제 추가 시 이 철학에 맞는지 검토해주세요.
